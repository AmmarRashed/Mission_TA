{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://preview.ibb.co/iDivJc/5529.png\" width='800' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: House Sales in King County, USA\n",
    "\n",
    "### https://www.kaggle.com/harlfoxem/housesalesprediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='7129300520', date='20141013T000000', price='221900', bedrooms='3', bathrooms='1', sqft_living='1180', sqft_lot='5650', floors='1', waterfront='0', view='0', condition='3', grade='7', sqft_above='1180', sqft_basement='0', yr_built='1955', yr_renovated='0', zipcode='98178', lat='47.5112', long='-122.257', sqft_living15='1340', sqft_lot15='5650')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ibmos2spark\n",
    "\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'api_key': 'fH7tipNa2VfJt4LO42GJU2-f65WmKRa0ZYn_H3sUnLU9',\n",
    "    'service_id': 'iam-ServiceId-5cf22436-1ea4-4a82-8752-22c7e7206d58',\n",
    "    'iam_service_endpoint': 'https://iam.ng.bluemix.net/oidc/token'}\n",
    "\n",
    "configuration_name = 'os_b0d31744b6c54747aec215514fff27a4_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(cos.url('kc_house_data.csv', 'cs340spring20184b12f92a8d204278af3959660617b691'))\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean your ... data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+----------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|        id|           date|     price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|grade|sqft_above|sqft_basement|yr_built|yr_renovated|zipcode|    lat|    long|sqft_living15|sqft_lot15|\n",
      "+----------+---------------+----------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|7129300520|20141013T000000|    221900|       3|        1|       1180|    5650|     1|         0|   0|        3|    7|      1180|            0|    1955|           0|  98178|47.5112|-122.257|         1340|      5650|\n",
      "|6414100192|20141209T000000|    538000|       3|     2.25|       2570|    7242|     2|         0|   0|        3|    7|      2170|          400|    1951|        1991|  98125| 47.721|-122.319|         1690|      7639|\n",
      "|5631500400|20150225T000000|    180000|       2|        1|        770|   10000|     1|         0|   0|        3|    6|       770|            0|    1933|           0|  98028|47.7379|-122.233|         2720|      8062|\n",
      "|2487200875|20141209T000000|    604000|       4|        3|       1960|    5000|     1|         0|   0|        5|    7|      1050|          910|    1965|           0|  98136|47.5208|-122.393|         1360|      5000|\n",
      "|1954400510|20150218T000000|    510000|       3|        2|       1680|    8080|     1|         0|   0|        3|    8|      1680|            0|    1987|           0|  98074|47.6168|-122.045|         1800|      7503|\n",
      "|7237550310|20140512T000000|1.225e+006|       4|      4.5|       5420|  101930|     1|         0|   0|        3|   11|      3890|         1530|    2001|           0|  98053|47.6561|-122.005|         4760|    101930|\n",
      "|1321400060|20140627T000000|    257500|       3|     2.25|       1715|    6819|     2|         0|   0|        3|    7|      1715|            0|    1995|           0|  98003|47.3097|-122.327|         2238|      6819|\n",
      "|2008000270|20150115T000000|    291850|       3|      1.5|       1060|    9711|     1|         0|   0|        3|    7|      1060|            0|    1963|           0|  98198|47.4095|-122.315|         1650|      9711|\n",
      "|2414600126|20150415T000000|    229500|       3|        1|       1780|    7470|     1|         0|   0|        3|    7|      1050|          730|    1960|           0|  98146|47.5123|-122.337|         1780|      8113|\n",
      "|3793500160|20150312T000000|    323000|       3|      2.5|       1890|    6560|     2|         0|   0|        3|    7|      1890|            0|    2003|           0|  98038|47.3684|-122.031|         2390|      7570|\n",
      "|1736800520|20150403T000000|    662500|       3|      2.5|       3560|    9796|     1|         0|   0|        3|    8|      1860|         1700|    1965|           0|  98007|47.6007|-122.145|         2210|      8925|\n",
      "|9212900260|20140527T000000|    468000|       2|        1|       1160|    6000|     1|         0|   0|        4|    7|       860|          300|    1942|           0|  98115|  47.69|-122.292|         1330|      6000|\n",
      "|0114101516|20140528T000000|    310000|       3|        1|       1430|   19901|   1.5|         0|   0|        4|    7|      1430|            0|    1927|           0|  98028|47.7558|-122.229|         1780|     12697|\n",
      "|6054650070|20141007T000000|    400000|       3|     1.75|       1370|    9680|     1|         0|   0|        4|    7|      1370|            0|    1977|           0|  98074|47.6127|-122.045|         1370|     10208|\n",
      "|1175000570|20150312T000000|    530000|       5|        2|       1810|    4850|   1.5|         0|   0|        3|    7|      1810|            0|    1900|           0|  98107|  47.67|-122.394|         1360|      4850|\n",
      "|9297300055|20150124T000000|    650000|       4|        3|       2950|    5000|     2|         0|   3|        3|    9|      1980|          970|    1979|           0|  98126|47.5714|-122.375|         2140|      4000|\n",
      "|1875500060|20140731T000000|    395000|       3|        2|       1890|   14040|     2|         0|   0|        3|    7|      1890|            0|    1994|           0|  98019|47.7277|-121.962|         1890|     14018|\n",
      "|6865200140|20140529T000000|    485000|       4|        1|       1600|    4300|   1.5|         0|   0|        4|    7|      1600|            0|    1916|           0|  98103|47.6648|-122.343|         1610|      4300|\n",
      "|0016000397|20141205T000000|    189000|       2|        1|       1200|    9850|     1|         0|   0|        4|    7|      1200|            0|    1921|           0|  98002|47.3089| -122.21|         1060|      5095|\n",
      "|7983200060|20150424T000000|    230000|       3|        1|       1250|    9774|     1|         0|   0|        4|    7|      1250|            0|    1969|           0|  98003|47.3343|-122.306|         1280|      8850|\n",
      "+----------+---------------+----------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- bedrooms: string (nullable = true)\n",
      " |-- bathrooms: string (nullable = true)\n",
      " |-- sqft_living: string (nullable = true)\n",
      " |-- sqft_lot: string (nullable = true)\n",
      " |-- floors: string (nullable = true)\n",
      " |-- waterfront: string (nullable = true)\n",
      " |-- view: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sqft_above: string (nullable = true)\n",
      " |-- sqft_basement: string (nullable = true)\n",
      " |-- yr_built: string (nullable = true)\n",
      " |-- yr_renovated: string (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- sqft_living15: string (nullable = true)\n",
      " |-- sqft_lot15: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgflip.com/294a8s.jpg\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf  # user defined function\n",
    "parse_date = udf(lambda date: date.split(\"T\")[0])\n",
    "df = df.withColumn(\"date\", parse_date(df.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: float (nullable = true)\n",
      " |-- date: float (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- bedrooms: float (nullable = true)\n",
      " |-- bathrooms: float (nullable = true)\n",
      " |-- sqft_living: float (nullable = true)\n",
      " |-- sqft_lot: float (nullable = true)\n",
      " |-- floors: float (nullable = true)\n",
      " |-- waterfront: float (nullable = true)\n",
      " |-- view: float (nullable = true)\n",
      " |-- condition: float (nullable = true)\n",
      " |-- grade: float (nullable = true)\n",
      " |-- sqft_above: float (nullable = true)\n",
      " |-- sqft_basement: float (nullable = true)\n",
      " |-- yr_built: float (nullable = true)\n",
      " |-- yr_renovated: float (nullable = true)\n",
      " |-- zipcode: float (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- long: float (nullable = true)\n",
      " |-- sqft_living15: float (nullable = true)\n",
      " |-- sqft_lot15: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    numeric_column = df[column].cast('float')\n",
    "    df = df.withColumn(column, numeric_column)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|          id|       date|   price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|grade|sqft_above|sqft_basement|yr_built|yr_renovated|zipcode|    lat|    long|sqft_living15|sqft_lot15|\n",
      "+------------+-----------+--------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "| 7.1293005E9|2.0141012E7|221900.0|     3.0|      1.0|     1180.0|  5650.0|   1.0|       0.0| 0.0|      3.0|  7.0|    1180.0|          0.0|  1955.0|         0.0|98178.0|47.5112|-122.257|       1340.0|    5650.0|\n",
      "|    6.4141E9|2.0141208E7|538000.0|     3.0|     2.25|     2570.0|  7242.0|   2.0|       0.0| 0.0|      3.0|  7.0|    2170.0|        400.0|  1951.0|      1991.0|98125.0| 47.721|-122.319|       1690.0|    7639.0|\n",
      "| 5.6315003E9|2.0150224E7|180000.0|     2.0|      1.0|      770.0| 10000.0|   1.0|       0.0| 0.0|      3.0|  6.0|     770.0|          0.0|  1933.0|         0.0|98028.0|47.7379|-122.233|       2720.0|    8062.0|\n",
      "|2.48720077E9|2.0141208E7|604000.0|     4.0|      3.0|     1960.0|  5000.0|   1.0|       0.0| 0.0|      5.0|  7.0|    1050.0|        910.0|  1965.0|         0.0|98136.0|47.5208|-122.393|       1360.0|    5000.0|\n",
      "|1.95440051E9|2.0150218E7|510000.0|     3.0|      2.0|     1680.0|  8080.0|   1.0|       0.0| 0.0|      3.0|  8.0|    1680.0|          0.0|  1987.0|         0.0|98074.0|47.6168|-122.045|       1800.0|    7503.0|\n",
      "+------------+-----------+--------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "## VectorAssembler is a transformer that combines a given list of columns into a single vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import Row\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list()\n",
    "for col in df.columns:\n",
    "    if 'price' in col or 'id' in col:continue\n",
    "    features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|   price|            features|\n",
      "+--------+--------------------+\n",
      "|221900.0|[2.0141012E7,3.0,...|\n",
      "+--------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=features,\n",
    "    outputCol=\"features\")\n",
    "\n",
    "processed_df = assembler.transform(df).select([\"price\",\"features\"])\n",
    "processed_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17315, 4298)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = processed_df.randomSplit([0.8, 0.2], seed=42)  # train test split\n",
    "train.count(),test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we predict the price of a house based on the other features?\n",
    "# create\n",
    "# fit\n",
    "# transform vs predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(price=75000.0, features=DenseVector([20150216.0, 1.0, 0.0, 670.0, 43377.0, 1.0, 0.0, 0.0, 3.0, 3.0, 670.0, 0.0, 1966.0, 0.0, 98022.0, 47.2638, -121.906, 1160.0, 42882.0]), scaled=DenseVector([1.4183, -2.5312, -2.7476, -1.5342, 0.6539, -0.9149, -0.087, -0.3064, -0.6297, -3.962, -1.3494, -0.6567, -0.1664, -0.2116, -1.0452, -2.1319, 2.1826, -1.2064, 1.0891]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled\", withMean=True, withStd=True)\n",
    "\n",
    "scaler_model = standard_scaler.fit(train)\n",
    "\n",
    "train_scaled = scaler_model.transform(train)\n",
    "test_scaled = scaler_model.transform(test)\n",
    "\n",
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|  price|            features|              scaled|\n",
      "+-------+--------------------+--------------------+\n",
      "|75000.0|[2.0150216E7,1.0,...|[1.41829140513976...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_scaled.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='scaled', labelCol='price') # create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(train_scaled) # fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([13606.0926, -31790.3253, 30115.8155, 1488517.6311, 6365.1685, 5481.8402, 50738.6515, 37825.4152, 18168.775, 110191.1272, -1197338.7843, -652990.4813, -75948.2601, 10039.1401, -31536.0726, 84295.9861, -29543.2436, 18403.0739, -11026.5998])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------------------+\n",
      "|  price|            features|              scaled|         prediction|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "|78000.0|[2.0140506E7,2.0,...|[-0.7679014231535...|-51504.086829517735|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.transform(test_scaled)\n",
    "preds.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = RegressionEvaluator(predictionCol='prediction', labelCol='price', metricName='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214653.21993681777"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.evaluate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 with Spark 2.1",
   "language": "python",
   "name": "python3-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
