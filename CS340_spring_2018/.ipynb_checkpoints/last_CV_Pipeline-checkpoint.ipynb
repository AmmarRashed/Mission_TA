{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam or Ham message classifier\n",
    "<img src=\"https://blog.codecentric.de/files/2016/06/ham-vs-spam.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row\n",
    "sc = SparkContext('local','example')\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_wheader = sc.textFile(\"data/spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1,v2,,,',\n",
       " 'ham,\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\",,,',\n",
       " 'ham,Ok lar... Joking wif u oni...,,,',\n",
       " \"spam,Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's,,,\",\n",
       " 'ham,U dun say so early hor... U c already then say...,,,']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_wheader.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the head\n",
    "header = rdd_wheader.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham,\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\",,,',\n",
       " 'ham,Ok lar... Joking wif u oni...,,,',\n",
       " \"spam,Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's,,,\",\n",
       " 'ham,U dun say so early hor... U c already then say...,,,',\n",
       " 'ham,\"Nah I don\\'t think he goes to usf, he lives around here though\",,,']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = rdd_wheader.filter(lambda row: row!=header)\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ham',\n",
       "  '\"Go until jurong point crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\"'],\n",
       " ['ham', 'Ok lar... Joking wif u oni...'],\n",
       " ['spam',\n",
       "  \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"],\n",
       " ['ham', 'U dun say so early hor... U c already then say...'],\n",
       " ['ham', '\"Nah I don\\'t think he goes to usf he lives around here though\"']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separated = rdd.map(lambda row: [row.split(\",\")[0]]+[''.join(row.split(\",\")[1:])])\n",
    "separated.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['ham',\n",
       "   '\"Go until jurong point crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\"'],\n",
       "  0),\n",
       " (['ham', 'Ok lar... Joking wif u oni...'], 1),\n",
       " (['spam',\n",
       "   \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"],\n",
       "  2),\n",
       " (['ham', 'U dun say so early hor... U c already then say...'], 3),\n",
       " (['ham', '\"Nah I don\\'t think he goes to usf he lives around here though\"'],\n",
       "  4)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_with_ids = separated.zipWithIndex()\n",
    "rdd_with_ids.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  1,\n",
       "  'go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'),\n",
       " (1, 1, 'ok lar joking wif u oni'),\n",
       " (2,\n",
       "  0,\n",
       "  'free entry in a wkly comp to win fa cup final tkts st may text fa to to receive entry question std txt rate t c s apply over s'),\n",
       " (3, 1, 'u dun say so early hor u c already then say'),\n",
       " (4, 1, 'nah i don t think he goes to usf he lives around here though')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "labels = lambda label: 1 if \"ham\" in label else 0\n",
    "cleaned_rdd = rdd_with_ids.map(lambda row: (row[1],labels(row[0][0]), \" \".join(re.findall(\"[a-zA-Z]+\", row[0][1])).lower()))\n",
    "cleaned_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+\n",
      "| id|label|             message|\n",
      "+---+-----+--------------------+\n",
      "|  0|    1|go until jurong p...|\n",
      "|  1|    1|ok lar joking wif...|\n",
      "|  2|    0|free entry in a w...|\n",
      "|  3|    1|u dun say so earl...|\n",
      "|  4|    1|nah i don t think...|\n",
      "+---+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = cleaned_rdd.toDF([\"id\",\"label\",\"message\"])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " \"a's\",\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = open(\"data/stopwords_en.txt\",\"r\").read().split(\"\\n\")\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Validation - Test\n",
    "<img src=\"https://blog.codecentric.de/files/2016/06/train-vs-test-768x363.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.9, 0.1], seed=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "<img src=\"https://memegenerator.net/img/instances/65014146.jpg\" width=400>\n",
    "<img src=\"https://i.stack.imgur.com/1fXzJ.png\">\n",
    "# Pipeline\n",
    "<img src=\"http://www.bbc.co.uk/staticarchive/6a2edaa3e3a9107131e33af1a7a2707860c32933.jpg\" width=500>\n",
    "<img src=\"https://databricks.com/wp-content/uploads/2015/01/pipeline-1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, StopWordsRemover\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Defining the pipeline\n",
    "tokenizer = Tokenizer(inputCol='message', outputCol='Words')\n",
    "removeStopWords = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='filtered_words', stopWords=stopwords)\n",
    "hashingTF = HashingTF(inputCol=removeStopWords.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "pipeline = Pipeline(stages=[tokenizer, removeStopWords, hashingTF, lr])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10, 100, 1000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "    \n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 78.88309955596924\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model = crossval.fit(train)\n",
    "print(\"Took:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|    1|       1.0|\n",
      "|    0|       0.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select([\"label\",\"prediction\"]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Honorable mention:\n",
    "https://blog.codecentric.de/en/2016/06/spam-classification-using-sparks-dataframes-ml-zeppelin-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "<img src=\"metrics.PNG\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area under ROC curve\n",
    "Receiver Operating Characteristic\n",
    "<img src=\"roc.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area under PR curve\n",
    "<img src=\"PR.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol=\"label\", metricName=\"accuracy\")\n",
    "f1 = MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol=\"label\", metricName=\"f1\")\n",
    "rmse = RegressionEvaluator(predictionCol=\"prediction\",labelCol=\"label\",metricName=\"rmse\")\n",
    "roc = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "prc = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\", metricName=\"areaUnderPR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.962432915921288\n",
      "f1: 0.960079062261531\n",
      "RMSE: 0.19382230026163652\n",
      "Area Under ROC Curve: 0.8719512195121951\n",
      "Area Under PR Curve: 0.9578313253012049\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\", accuracy.evaluate(prediction))\n",
    "print(\"f1:\", f1.evaluate(prediction))\n",
    "print(\"RMSE:\", rmse.evaluate(prediction))\n",
    "print(\"Area Under ROC Curve:\", roc.evaluate(prediction))\n",
    "print(\"Area Under PR Curve:\", prc.evaluate(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://img00.deviantart.net/0248/i/2013/295/d/8/that_s_all_folks__by_surrimugge-d6rfav1.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
